\newpage
\section{Технический отчет по практике}

\subsection{Постановка задачи}

С использованием искуственной нейронной сети (ИНС) Fuzzy ART реализовать ПМО обеспечения, позволяющее классифицировать символы русского алфавита.

\subsection{Описание парадигмы Fuzzy ART}


Нейронные сети адаптивной резонансной теории (Adaptive Resonance Theory = ART) или ART-сети образуют целый класс различных нейросетей, предложенных Карпентером (Carpenter) и Гроссбергом (Grossberg) (Бостонский университет, 1987-1991).

В реальной практике часто данные, используемые для обучения или самообучения сети, не стабильны. В этом случае классические нейронные сети не позволят получить требуемого результата.

При анализе систем классификации возникают противоречивые требования или свойства нейросети. С одной стороны очень важно, чтобы она была способна выявлять (обнаруживать) образы новых классов, ранее не представленных сети. Это свойство пластичности. С другой же стороны изученные классы образов должны сохраняться – свойство устойчивости работы нейросетей. Эти два свойства – пластичности и стабильности в известной мере противоречивы – дилемма пластичности-стабильности. Сети ART были разработаны для разрешения этой дилеммы, а именно: для установления новых ассоциаций (классов) нейронной сетью без забывания старых ассоциаций (классов). Семейство ART-сетей включает следующие сети:
\begin{itemize} \compact
	\item ART-1: для бинарных входных векторов, когда признаки распознаваемых образов принимают два значения 1 или 0;
	\item ART-2: расширение ART-1-сетей на непрерывные входные векторы;
	\item ART-2a: оптимальная версия ART-2-сетей, отличающаяся повышенной скоростью сходимости;
	\item ART-3: моделирование временных и химических процессов (биологических механизмов) на базе ART-2;
	\item ARTMAP: комбинация двух ART-сетей (например, ART-1 и ART-2);
	\item FuzzyART: гибридная сеть, объединяющая нечеткую логику (Fuzzy Logik) и ART- сети.
\end{itemize}


Принцип работы ART-сетей сравнительно прост. При вводе значений признаков некоторого образа ART-1-сеть пытается сопоставить ему некоторый класс из числа уже изученных. Если такой класс удается найти, то производится сравнительно небольшая модификация прототипа (стереотипа, типичного представителя) этого класса для того, чтобы он хорошо отображал и новый образ. В этом случае классификация образа на этом заканчивается.
Если же такой класс найти не удается, то образуется (вводится) новый класс. При этом предъявленный образ несколько модифицируется и используется затем в качестве прототипа (стереотипа, типичного представителя) для нового класса. При этом уже изученные классы не изменяются. 

Сеть  Fuzzy  ART  является  расширением  сети ART-1  путем  применения  теории  нечетких  множеств, что позволяет новой сети работать как с бинарными, так и с аналоговыми входными образами. Для Fuzzy ART основные фазы классификации 
следующие.

\textit{Предварительная  обработка}.  Все  величины входного образа должны быть в интервале $[0,1]$ 
$$
	i_k \in [0,1] \forall k
$$

\textit{Распознавание}. Восходящая сетевая активность, ведущая  к  предварительному  выбору  прототипа, определяется  с  использованием  нечеткой  конъюнкции $\wedge$, по формулам:
$$
	x \wedge y = \min\{x,y\}
$$
$$
	X \wedge Y = \min\{x_1 \wedge y_1, \ldots, x_m \wedge y_m\}
$$
где $Y$ – нечеткое подмножество $X$, если $X \wedge Y = Y$. Размер вектора $(|X|)$ определяется его нормой L1, т. е. суммой его элементов.

Активность $t_j$, каждого нейрона можно рассматривать как степень принадлежности прототипа $W_j$ нечеткому подмножеству входного образа $I$
$$
	t_j = \frac{|I \wedge W_j|}{\alpha + |W_j|}
$$ 
где $\alpha = const$ – величина, играющая регуляризующую роль, т.е. предотвращающая возникновение переполнения при операции деления при  $|W_j| \to 0$. 

\textit{Сравнение}. Сходство между входом $I$ и победившим прототипом $W_j$ определяется степенью принадлежности образа $I$ нечеткому подмножеству $W_j$. 
Адаптация происходит, если
$$
	\rho < \frac{|I \wedge W_j|}{|I|}
$$ 

\textit{Адаптация}. Адаптация победившего прототипа $W_j$ происходит путем изменения его компонентов по отношению к вектору $I \wedge W_j$:
$$
	W_j^{(new)} = \eta (I \wedge W_j^{(old)}) + (1 - \eta) W_j^{(old)}
$$
где $\eta \in [0,1]$ – показатель обучения, определяющий скорость сходимости прототипов к общему минимуму значений элементов всех входных образов, 
принадлежащих одному классу.

Сеть  ART  может  работать  в  режиме  классификации,  если  для  предварительно  обученной сети установить $\eta = 0$, что предотвратит модификацию  прототипов  новыми  входными  образами. Начальная инициализация прототипов  выполняется постоянной величиной
$$
	w_{ij} \geq 1 \forall i
$$

Таким  образом  обеспечивается  поиск  сначала среди фиксированных прототипов, а затем - среди остальных. Часто используемый метод ускорения обучения  в  сетях  ART  это  установка  коэффициента обучения $\eta = 1$, когда прежде неиспользованный прототип адаптируется к текущему входному вектору. Входной вектор $I$ становится первым прототипом в новом классе, если другие ранее сформированные прототипы не подходят. Однако уже сформированные  прототипы  должны  адаптироваться  более  медленно  $(\eta  <  1)$,  чтобы  предотвратить их искажение зашумленными входными образами.

\textit{Дополнительное кодирование}. В сети Fuzzy ART существует  проблема  кластерного  распространения,  состоящая  в  том,  что  поскольку  векторные
элементы  прототипов  после  адаптации  только уменьшаются,  сеть  стремится  создавать  больше прототипов,  которые  соответствуют  входным  образам с большими значениеми входных величин, тогда как прототипы с малыми значениями могут 
никогда не быть доступны. Это устраняется путем нормализации,  например,  путем  нормализации входных образов.

Обычно  используется  модифицированный  вариант  нормализации,  называемый  дополнительным кодированием, который преобразовывает все входные образы к одинаковой длине вектора. При этом оригинальный вектор  $A=(a_1, \dots ,a_k  )$ кодируется во входной образ  $I=(i_1, \ldots, i_m)$ с добавлением своих дополнительных элементов к оригинальному вектору. Это удваивает длину всех входных образов и прототипов
$$
	I = (A,A^C) = (a_1, \ldots, a_k, 1-a_1, \ldots, 1-a_k) \quad a_i \in [0,1] \forall i
$$

Норма $L1$ векторов, закодированных этим методом  и  имеющих  одинаковую  длину,  является величиной постоянной, независимой от  величин элементов
$$
	|I| = \sum_{i=1}^2k i_i = \sum_{i=1}^k a_i + \sum_{i=1}^k (1 - a_i) = \sum_{i=1}^k a_i + k - \sum_{i=1}^k a_i = k = m / 2 
$$

Использование  дополнительного  кодирования упрощает выражение:
$$
	\rho \leq \frac{I \wedge W_j}{k}
$$




\subsection{Состав и описание ПМО}

Программно-математическое обеспечение разрабатывалось в среде математического программирования Matlab.


%    ARTMAP_Add_New_Category - Adds a new category to the ARTMAP network.
%    ARTMAP_Classify - Uses a trained ARTMAP network to classify a dataset.
%    ARTMAP_Create_Network - Creates the ARTMAP network.
%    ARTMAP_Learn - Trains a given ARTMAP network on a dataset.

% Functions required by this software:
%    ART_Activate_Categories - Required by ARTMAP_Classify and ARTMAP_Learn
%    ART_Calculate_Match - Required by ARTMAP_Classify and ARTMAP_Learn
%    ART_Complement_Code - Required if complement coding of inputs is used
%    ART_Update_Weights - Required by ARTMAP_Learn

% Description of the system architecture:
%    The above set of functions is used to create, train, and use an ARTMAP
%    network to classify a dataset. While all of the functions are 
%    necessary, only three of them are meant to be called by the user. 
%    Those functions are as follows:

%    Functions available to user:
%        ARTMAP_Classify
%        ARTMAP_Create_Network
%        ARTMAP_Learn


\subsection{Тестирование ПМО}


\subsection{Анализ результатов}
